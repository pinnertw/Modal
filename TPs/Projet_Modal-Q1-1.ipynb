{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changer :\n",
    "Définition de saut,\n",
    "Ruines 1-1 numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1gxAXcgYBTY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN5LC1dmz9LE"
   },
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6x5boyyXei6"
   },
   "source": [
    "Dans cette première modélisation simplifiée, on considère donc que le prix $P_t$ est un processus de Poisson de paramètres $\\lambda, \\nu$ où $\\nu$ est la loi des incréments $J_n$. \n",
    "\n",
    "Pour un temps d'attente moyen entre deux sauts de $300s$, on prend $\\lambda = \\dfrac{1}{300}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XO0iJelvzaxI"
   },
   "source": [
    "### Q1 -1 Probabilité de ruine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On identifie le processus par le processus de Poisson composé, qui finit à un temps fixé T\n",
    "# On crée des fonctions pour modéliser le processus.\n",
    "\n",
    "#### On définit nu, la loi des incréments\n",
    "# Ancien : plus lent\n",
    "saut_1_ancien = lambda x: np.random.choice([-1, 1], size=x, replace=True, p=[0.5, 0.5]) #correspond à m=1\n",
    "saut_2_ancien = lambda x: np.random.choice([-3, -2, -1, 1, 2, 3], size=x, replace=True, p=0.5*np.array([1/6, 1/3, 1/2, 1/2, 1/3, 1/6])) #correspond à m=3\n",
    "\n",
    "# Nouveau : beaucoup plus vite\n",
    "value_1 = np.array([-1, 1])\n",
    "value_2 = np.array([-3, -2, -2, -1, -1, -1, 1, 1, 1, 2, 2, 3])\n",
    "saut_1 = lambda x : value_1[np.random.randint(low=2, size=x)]\n",
    "saut_2 = lambda x : value_2[np.random.randint(low=12, size=x)]\n",
    "\n",
    "# Les paramètres\n",
    "P0 = 35\n",
    "T = 4*60*60\n",
    "lamb = 1/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Echantillionage d'importance\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)# Function is compiled to machine code when called the first time\n",
    "def inf_echantillon_importance(N, J, P0, lambT, s, f_dic): \n",
    "  ruines = 0.\n",
    "  ruines_carre = 0.\n",
    "  for i in range(len(N) - 1):\n",
    "    somme = P0\n",
    "    ruine = 0.\n",
    "    ruine_carre = 0.\n",
    "    for j in range(N[i], N[i + 1]):\n",
    "      somme += J[j]\n",
    "      if somme < 0:\n",
    "        # Calculer L_T\n",
    "        X_T_f = np.sum(f_dic[ J[N[i]:N[i+1]] ])\n",
    "        L_T = np.exp(X_T_f - (s - 1) * lambT)\n",
    "        ruine = 1 / L_T\n",
    "        ruine_carre = 1 / L_T / L_T\n",
    "        break\n",
    "    ruines += ruine\n",
    "    ruines_carre += ruine_carre\n",
    "  return ruines, ruines_carre\n",
    "\n",
    "def trajectoire_importance(P0, T, lamb, m, size, f):\n",
    "  if m == 1:\n",
    "    value = np.array([-1, 1])\n",
    "    p = np.array([1/2, 1/2])\n",
    "  else:\n",
    "    value = np.array([-3, -2, -1, 1, 2, 3])\n",
    "    p = np.array([1 / 12, 1 / 6, 1 / 4, 1 / 4, 1 / 6, 1 / 12])\n",
    "    \n",
    "  # Nouvelle loi\n",
    "  s = np.sum(np.exp(f[value]) * p)\n",
    "  new_lamb = lamb * s\n",
    "  new_p = np.exp(f[value]) * p / s\n",
    "\n",
    "  N = np.random.poisson(lam=new_lamb * T, size=size + 1)\n",
    "  N[0] = 0\n",
    "  N = N.cumsum()                    # La valeur N[i] - N[i - 1] est égale à Ni pour le i-ième échantillon\n",
    "                                    # Donc la somme des sauts entre indice N[i] et N[i + 1] - 1 suit la loi voulue\n",
    "  \n",
    "  J = np.random.choice(value, size=N[-1] + 1, p=new_p)\n",
    "  ruines, ruines_carre = inf_echantillon_importance(N, J, P0, lamb * T, s, f)\n",
    "  proba = ruines / size\n",
    "  R_IC = 1.96 * (ruines_carre / size - proba * proba) / np.sqrt(size)\n",
    "  return proba, R_IC\n",
    "\n",
    "def meilleur_coeff(m, func, l_ = -100, r_ = 100):\n",
    "    \n",
    "    # f_dic : un map de p à f[p]. La forme étant [f[0], f[1], f[2], f[3], f[-3], f[-2], f[-1]] ou [f[0], f[1], f[-1]]\n",
    "    if m == 3:\n",
    "      value = np.array([-3, -2, -1, 1, 2, 3])\n",
    "      p = np.array([1 / 12, 1 / 6, 1 / 4, 1 / 4, 1 / 6, 1 / 12])\n",
    "      f_dic = np.array([0, 1, 2, 3, -3, -2, -1])\n",
    "    else:\n",
    "      value = np.array([-1, 1])\n",
    "      p = np.array([0.5, 0.5])\n",
    "      f_dic = np.array([0, 1, -1])\n",
    "\n",
    "    l = l_\n",
    "    f = func(f_dic, l)\n",
    "    print(\"l =\", l, \"\\tEspérance =\", P0 / (lamb * T) + np.sum(value * np.exp(f[value]) * p))\n",
    "    r = r_\n",
    "    f = func(f_dic, r)\n",
    "    print(\"r =\", r, \"\\tEspérance =\", P0 / (lamb * T) + np.sum(value * np.exp(f[value]) * p))\n",
    "    r_sign = np.sign(P0 / (lamb * T) + np.sum(value * np.exp(f[value]) * p))\n",
    "    while r - l > 1e-6:\n",
    "      c = (r + l) / 2\n",
    "      f = func(f_dic, c)\n",
    "      if np.sign(P0 / (lamb * T) + np.sum(value * np.exp(f[value]) * p)) == r_sign:\n",
    "        r = c\n",
    "      else:\n",
    "        l = c\n",
    "    print(\"c =\", c, \"Espérance =\", P0 / (lamb * T) + np.sum(value * np.exp(f[value]) * p))\n",
    "\n",
    "    p_r, R_IC = trajectoire_importance(P0, T, lamb, m, M, f)\n",
    "\n",
    "    print(\"Probabilité :\", p_r)\n",
    "    print(\"Rayon de l'intervalle de confiance :\", R_IC)\n",
    "    print(\"Intervalle de confiance : [{}, {}]\".format(p_r - R_IC, p_r + R_IC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l = -100 \tEspérance = -4.8560659881031396e+129\n",
      "r = 100 \tEspérance = 4.8560659881031396e+129\n",
      "c = -0.2096913754940033 Espérance = -2.6540470312585995e-06\n",
      "Probabilité : 0.004320649739227504\n",
      "Rayon de l'intervalle de confiance : 2.533475460215391e-07\n",
      "Intervalle de confiance : [0.004320396391681482, 0.004320903086773526]\n",
      "CPU times: user 1.2 s, sys: 262 ms, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Les paramètres\n",
    "P0 = 35\n",
    "T = 4*60*60\n",
    "lamb = 1/300\n",
    "m = 3\n",
    "M = int(1e6)\n",
    "\n",
    "################### f(x) = c *  x #######################\n",
    "meilleur_coeff(m, lambda x, c: x * c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l = -10 \tEspérance = -4.544123462847749e+116\n",
      "r = 10 \tEspérance = 4.544123462847749e+116\n",
      "c = -0.03409087657928467 Espérance = 1.4896594524471674e-05\n",
      "Probabilité : 0.004332922036639704\n",
      "Rayon de l'intervalle de confiance : 2.673946739536795e-06\n",
      "Intervalle de confiance : [0.004330248089900167, 0.00433559598337924]\n",
      "CPU times: user 1.24 s, sys: 247 ms, total: 1.48 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################### f(x) = c * x ** 3 #######################\n",
    "meilleur_coeff(m, lambda x, c: c * x ** 3, -10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ljp4VlmzfJ4"
   },
   "outputs": [],
   "source": [
    "## Monte-Carlo Naif avec numba\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def inf_echantillon(N, J, P0): # Function is compiled to machine code when called the first time\n",
    "  ruines = 0\n",
    "  for i in range(len(N) - 1):\n",
    "    somme = P0\n",
    "    ruine = 0\n",
    "    for j in range(N[i], N[i + 1]):\n",
    "      somme += J[j]\n",
    "      if somme < 0:\n",
    "        ruine = 1\n",
    "        break\n",
    "    ruines += ruine\n",
    "  return ruines\n",
    "\n",
    "def trajectoire(P0, T, lamb, saut, size):\n",
    "  if size > int(1e7):\n",
    "    sizes = size\n",
    "    size = int(1e7)\n",
    "    proba = 0\n",
    "    for i in range(sizes // size):\n",
    "      N = np.random.poisson(lam=lamb * T, size=size + 1)\n",
    "      N[0] = 0\n",
    "      N = N.cumsum()                    # La valeur N[i] - N[i - 1] est égale à Ni pour le i-ième échantillon\n",
    "                                        # Donc la somme des sauts entre indice N[i] et N[i + 1] - 1 suit la loi voulue\n",
    "      J = saut(N[-1] + 1)\n",
    "      res = inf_echantillon(N, J, P0)\n",
    "      proba += res / size / (sizes // size)\n",
    "    return proba\n",
    "  else:\n",
    "    N = np.random.poisson(lam=lamb * T, size=size + 1)\n",
    "    N[0] = 0\n",
    "    N = N.cumsum()                    # La valeur N[i] - N[i - 1] est égale à Ni pour le i-ième échantillon\n",
    "                                      # Donc la somme des sauts entre indice N[i] et N[i + 1] - 1 suit la loi voulue\n",
    "    J = saut(N[-1] + 1)\n",
    "    res = inf_echantillon(N, J, P0)\n",
    "    proba = res / size\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "gL8w_R_83lQb",
    "outputId": "6b0f3a12-8fa7-40a8-9853-cc783a28bf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004342\n",
      "0.00012887125999809886\n",
      "CPU times: user 593 ms, sys: 117 ms, total: 710 ms\n",
      "Wall time: 711 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "M = int(1e6)\n",
    "p_r = trajectoire(P0, T, lamb, saut_2, size=M)\n",
    "R_IC = 1.96*np.sqrt(p_r*(1-p_r))/np.sqrt(M) #rayon de l'intervalle de confiance\n",
    "print(p_r)\n",
    "print(R_IC)\n",
    "\n",
    "#print(trajectoire(P0, T, lamb, saut_1, size=int(1e7)))\n",
    "\n",
    "#m=1\n",
    "#0.00279 pour P0 = 20 M = 10^5 (total time 161 ms)\n",
    "#5e-07 pour P0=35 et M=10^7 total time : 16.1 s\n",
    "#quand on fait la moyenne sur 10 essais à M=10^7, on trouve proba_emp = 2.009975 e-7 et sigma_emp = 3.6 e-7 (tout ça pour m=1)\n",
    "\n",
    "#m=3\n",
    "#proba_emp=0.0043245, sigma_emp = 7.1273066441679e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEpbJndTyvwM"
   },
   "outputs": [],
   "source": [
    "## Splitting et MCMC - Méthode 3\n",
    "def NiveauxSplitting(a,seuil,M1,lamb,T,p,P0,saut):\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction qui renvoie une estimation des niveaux\n",
    "    de splitting a_1, a_2, ..., a_k tels que P(Phi_T <= a_k | Phi_T <= a_{k-1}) = 0.1 = seuil\n",
    "    (où Phi_T : inf de P_t pour t dans [0;T])\n",
    "    Ces niveaux sont des quantiles d'une loi conditionnelle.\n",
    "    On utilise l'inversion de la fonction de repartition empirique de \n",
    "    cette loi afin d'estimer un quantile par\n",
    "    le quantile empirique.\n",
    "    On a a = a_k < a_{k-1} < ... < a_0= + infini (dans notre problème, a = 0)\n",
    "    La fonction renvoie quantiles = [a_1, ..., a_k]\n",
    "    \"\"\"\n",
    "    ## Estimation du premier niveau a_1: c'est le \n",
    "    ## quantile d'une loi non conditionnelle.\n",
    "    ## On l'estime ici par la methode ergodique\n",
    "\n",
    "    liste_Phi = np.zeros(M1)\n",
    "\n",
    "    liste_sauts = liste_sts(lamb,T,saut)\n",
    "    liste_sauts_min = None\n",
    "    Phi_min = 100000\n",
    "    \n",
    "    for l in range(M1):\n",
    "        coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "\n",
    "        liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "        nc = coloriage.shape[1]\n",
    "        nt = liste_sauts_tilde.shape[1]\n",
    "        new_liste_sauts = np.zeros((2, nc + nt))\n",
    "        new_liste_sts(coloriage, liste_sauts_tilde, new_liste_sauts, nc, nt)\n",
    "        #new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "        #new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "        liste_sauts = new_liste_sauts\n",
    "        liste_Phi[l] = Phi(liste_sauts,P0)\n",
    "        if liste_Phi[l] < Phi_min:\n",
    "            liste_sauts_min = np.copy(liste_sauts)\n",
    "            Phi_min = liste_Phi[l]\n",
    "\n",
    "    liste_Phi.sort()\n",
    "    \n",
    "    quantiles = np.array([liste_Phi[int(np.ceil(seuil*M1))-1]])    \n",
    "\n",
    "    while quantiles[-1] > a:\n",
    "        #print(\"Inside while\")\n",
    "        liste_Phi = np.zeros(M1)\n",
    "        \n",
    "        liste_sauts = np.copy(liste_sauts_min)\n",
    "        Phi_min = 100000\n",
    "\n",
    "        ## Simulation du processus AR(1) conditionnel\n",
    "    \n",
    "        for l in range(M1):\n",
    "            coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "            liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "            \n",
    "            nc = coloriage.shape[1]\n",
    "            nt = liste_sauts_tilde.shape[1]\n",
    "            new_liste_sauts = np.zeros((2, nc + nt))\n",
    "            new_liste_sts(coloriage, liste_sauts_tilde, new_liste_sauts, nc, nt)\n",
    "            #new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "            #new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "            if Phi(new_liste_sauts,P0)<quantiles[-1]:\n",
    "                liste_sauts = new_liste_sauts\n",
    "\n",
    "            liste_Phi[l] = Phi(liste_sauts,P0)\n",
    "            if liste_Phi[l] < Phi_min:\n",
    "                liste_sauts_min = np.copy(liste_sauts)\n",
    "                Phi_min = liste_Phi[l]\n",
    "\n",
    "        liste_Phi.sort()\n",
    "        quantiles = np.append(quantiles, liste_Phi[int(np.ceil(seuil*M1))-1] )\n",
    "\n",
    "    \n",
    "    ## On selectionne les niveaux a_{k-1},..., a_1 strictement au dessus de a\n",
    "    quantiles = quantiles[:-1]\n",
    "    ## On rajoute a\n",
    "    quantiles = np.append(quantiles,a)\n",
    "\n",
    "    return quantiles\n",
    "\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def Phi(liste_sauts, P0): # Function is compiled to machine code when called the first time\n",
    "    prix_min = P0\n",
    "    if len(liste_sauts[0]) == 0:\n",
    "        return P0\n",
    "    for i in liste_sauts[1, :]:\n",
    "        P0 += i\n",
    "        if P0 < prix_min:\n",
    "            prix_min = P0\n",
    "    return prix_min\n",
    "\n",
    "'''def Phi(liste_sauts,P0):#fonction qui renvoie l'inf des valeurs de X aux instants de saut\n",
    "    #ie l'inf de P0+cumsum(incréments) \n",
    "    if len(liste_sauts[0]) == 0:\n",
    "        return P0\n",
    "    liste_prix = P0+np.cumsum(liste_sauts[1,:])\n",
    "    prix_min = np.min(liste_prix)\n",
    "    return prix_min'''\n",
    "\n",
    "def liste_sts(lbda, T, saut):\n",
    "    N = np.random.poisson(lbda*T)\n",
    "    liste_sauts = np.zeros((2, N))\n",
    "    liste_sauts[0, :] = np.sort(np.random.uniform(low=0, high=T, size=N))\n",
    "    liste_sauts[1, :] = saut(N)\n",
    "    #renvoie un array de N colonnes et 2 lignes: 1ere ligne pour les temps des sauts (T_n), deuxième ligne pour leurs amplitudes (J_n)\n",
    "    return liste_sauts\n",
    "    #liste_temps_sauts = np.random.uniform(low = 0, high = T, size = N)\n",
    "    #liste_temps_sauts_triee = [np.sort(liste_temps_sauts)]\n",
    "    #liste_increments = [saut(N)]\n",
    "    #return np.concatenate((liste_temps_sauts_triee,liste_increments),axis=0)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def new_liste_sts(coloriage, liste_sauts_tilde, new_liste_sauts, nc, nt):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    # Merge two listes triées\n",
    "    while i < nc:\n",
    "        T1 = coloriage[0, i]\n",
    "        while j < nt and liste_sauts_tilde[0, j] < T1:\n",
    "            new_liste_sauts[:, k] = liste_sauts_tilde[:, j]\n",
    "            j += 1\n",
    "            k += 1\n",
    "        new_liste_sauts[:, k] = coloriage[:, i]\n",
    "        i += 1\n",
    "        k += 1\n",
    "    while j < nt:\n",
    "        new_liste_sauts[:, k] = liste_sauts_tilde[:, j]\n",
    "        j += 1\n",
    "        k += 1\n",
    "    return new_liste_sauts\n",
    "\n",
    "def tri_temps(new_liste_sauts):\n",
    "    ordre = [new_liste_sauts[0,:].argsort()]\n",
    "    liste_sauts_triee = np.take_along_axis(new_liste_sauts, np.concatenate((ordre,ordre),axis=0), axis=1) \n",
    "    return liste_sauts_triee\n",
    "\n",
    "\n",
    "def MCMC(M2,p,lamb,liste_a,P0,saut):\n",
    "\n",
    "    liste_pi = np.zeros(len(liste_a)) #estimateurs des probabilités conditionnelles\n",
    "\n",
    "    liste_indicatrices = np.zeros(M2,dtype=bool) \n",
    "    \"\"\"\n",
    "    le k-ieme élém. de liste_indicatrices vaut True si le prix devient négatif avant l'instant T lors du k-ieme essai; False sinon\n",
    "    \"\"\"\n",
    "\n",
    "    #Loi non conditionnelle\n",
    "    \n",
    "    liste_sauts = liste_sts(lamb,T,saut)\n",
    "    liste_sauts_min = None\n",
    "    Found = False\n",
    "\n",
    "    for l in range(M2):\n",
    "        coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "        liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "        \n",
    "        nc = coloriage.shape[1]\n",
    "        nt = liste_sauts_tilde.shape[1]\n",
    "        new_liste_sauts = np.zeros((2, nc + nt))\n",
    "        new_liste_sts(coloriage, liste_sauts_tilde, new_liste_sauts, nc, nt)\n",
    "        #new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "        #new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "        liste_sauts = new_liste_sauts\n",
    "        if Phi(liste_sauts, P0) < liste_a[0]:\n",
    "            liste_indicatrices[l] = True\n",
    "            if not Found:\n",
    "                liste_sauts_min = np.copy(liste_sauts)\n",
    "                Found = True\n",
    "\n",
    "    liste_pi[0] = np.mean(liste_indicatrices)\n",
    "    \n",
    "    for k in range(1,len(liste_a)):\n",
    "        liste_indicatrices = np.zeros(M2,dtype=bool)  \n",
    "\n",
    "        #Initialisation \n",
    "        liste_sauts = np.copy(liste_sauts_min)\n",
    "        Found = False\n",
    "\n",
    "      \n",
    "        for l in range(M2):\n",
    "            coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "\n",
    "            liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "\n",
    "            nc = coloriage.shape[1]\n",
    "            nt = liste_sauts_tilde.shape[1]\n",
    "            new_liste_sauts = np.zeros((2, nc + nt))\n",
    "            new_liste_sts(coloriage, liste_sauts_tilde, new_liste_sauts, nc, nt)\n",
    "            #new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "            #new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "            if Phi(new_liste_sauts,P0)< liste_a[k-1]:\n",
    "                liste_sauts = new_liste_sauts\n",
    "\n",
    "            if Phi(liste_sauts, P0) < liste_a[k]:\n",
    "                liste_indicatrices[l] = True\n",
    "                if not Found:\n",
    "                    liste_sauts_min = np.copy(liste_sauts)\n",
    "\n",
    "        liste_pi[k] = np.mean(liste_indicatrices)\n",
    "    \n",
    "    proba_prix_negatif = np.prod(liste_pi)\n",
    "    return proba_prix_negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NbRoSLDPkPMB",
    "outputId": "aecba370-6233-4de4-96c1-fca931b9c36e"
   },
   "outputs": [],
   "source": [
    "P0 = 35 \n",
    "T = 4*60*60 #conversion en secondes\n",
    "lamb =  1/300 \n",
    "M1 = int(1e3) \n",
    "M2 = int(1e5)\n",
    "n = 10\n",
    "a=0\n",
    "#Choix des paramètres pour les niveaux de splitting et la simulation par chaîne de Markov\n",
    "seuil = 0.03\n",
    "p=0.5\n",
    "\n",
    "def Splitting_Q1_1(a, seuil, M1, M2, n, lamb, T, p, P0, saut):\n",
    "    liste_a = NiveauxSplitting(a,seuil,M1,lamb,T,p,P0,saut)\n",
    "    #print(liste_a)\n",
    "    probas = np.zeros(n)\n",
    "    from tqdm.notebook import tqdm\n",
    "    for i in tqdm(range(n)):\n",
    "        probas[i] = MCMC(M2, p, lamb, liste_a, P0, saut)\n",
    "    #proba_emp = np.mean(probas)\n",
    "    #sigma_emp = np.std(probas) / np.sqrt(n) #écart-type empirique de la moyenne des n estimateurs\n",
    "    #print(proba_emp)\n",
    "    #print(sigma_emp)\n",
    "    #print(\"Estimation de la probabilité de ruine pour m=1 par méthode de Splitting/MCMC: {:09.8f}+/-{:09.8f}\".format(proba_emp,sigma_emp))\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dKnmd80stXp4",
    "outputId": "421f5a86-65b5-43d2-b834-b3351a7441a0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc71e23faf9b4e8b82b475cfdb30a24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 42.6 s, sys: 995 µs, total: 42.6 s\n",
      "Wall time: 42.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Splitting_Q1_1(a, seuil, M1, M2, n, lamb, T, p, P0, saut_1)\n",
    "#Réponse pour m=1 ie k=0 et P0=35 : proba = 3.333674930684664e-07, variance = 5 10^-8\n",
    "#m=3 et P0=35: proba = 0.004309577501008395, variance = 0.00010259619121779947\n",
    "#m=1 liste_a = [24. 17. 12.  7.  3.  0.] seuil =0.1 M=10^4 n=10 proba_emp=4.619226215866903e-07 sigma_emp= 9.561801048257746e-08\n",
    "#m=1 liste_a= [20. 12.  5.  0.] seuil = 0.03 P0=35 M=10^4 n=10 proba_emp = 3.6218700696e-07 sigma_emp = 7.599237232859178e-08 \n",
    "#same avec M=10^5 proba_emp = 3.4354401671979703e-07. sigma_emp= 1.3033966706232877e-08 LE MEILLEUR QU ON AIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with seuil = 0.01, p = 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be51231e09314a3ab541912c469a9768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-22a82d7476cb>\u001b[0m in \u001b[0;36mSplitting_Q1_1\u001b[0;34m(a, seuil, M1, M2, n, lamb, T, p, P0, saut)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mprobas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliste_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mproba_emp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msigma_emp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#écart-type empirique de la moyenne des n estimateurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-99e31c91372c>\u001b[0m in \u001b[0;36mMCMC\u001b[0;34m(M, p, lamb, liste_a, P0, saut)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mcoloriage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mliste_sauts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliste_sauts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mliste_sauts_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mliste_sts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seuils = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "ps = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "proba = np.zeros((len(seuils), len(ps), n))\n",
    "\n",
    "for i in range(len(seuils)):\n",
    "  seuil = seuils[i]\n",
    "  for j in range(len(ps)):\n",
    "    p = ps[j]\n",
    "    print(\"Processing with seuil = {}, p = {}\".format(seuil, p))\n",
    "    proba[i][j] = Splitting_Q1_1(a, seuil, M1, M2, n, lamb, T, p, P0, saut_1)\n",
    "np.save(\"probas\", proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yXOlLPEjIbD9",
    "outputId": "d0d2b7dc-d123-4604-9ee4-cb0f9c9d08a5"
   },
   "outputs": [],
   "source": [
    "print(\"Estimation de la probabilité de ruine pour m=1 par méthode de Splitting/MCMC: {:09.8f}+/-{:09.8f}\".format(proba_emp,sigma_emp))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "XO0iJelvzaxI",
    "cCgK9NrFzQfO",
    "f6ZpnHtBhElE",
    "ntNKzkWPzUT1",
    "fKihS64UzPW5",
    "GoJBPfJ4T0FL",
    "GiQmq9gl0gSv"
   ],
   "machine_shape": "hm",
   "name": "Projet_Modal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
