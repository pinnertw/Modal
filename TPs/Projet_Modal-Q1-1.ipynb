{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changer :\n",
    "Définition de saut,\n",
    "Ruines 1-1 numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1gxAXcgYBTY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN5LC1dmz9LE"
   },
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6x5boyyXei6"
   },
   "source": [
    "Dans cette première modélisation simplifiée, on considère donc que le prix $P_t$ est un processus de Poisson de paramètres $\\lambda, \\nu$ où $\\nu$ est la loi des incréments $J_n$. \n",
    "\n",
    "Pour un temps d'attente moyen entre deux sauts de $300s$, on prend $\\lambda = \\dfrac{1}{300}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XO0iJelvzaxI"
   },
   "source": [
    "### Q1 -1 Probabilité de ruine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On identifie le processus par le processus de Poisson composé, qui finit à un temps fixé T\n",
    "# On crée des fonctions pour modéliser le processus.\n",
    "\n",
    "#### On définit nu, la loi des incréments\n",
    "# Ancien : plus lent\n",
    "saut_1_ancien = lambda x: np.random.choice([-1, 1], size=x, replace=True, p=[0.5, 0.5]) #correspond à m=1\n",
    "saut_2_ancien = lambda x: np.random.choice([-3, -2, -1, 1, 2, 3], size=x, replace=True, p=0.5*np.array([1/6, 1/3, 1/2, 1/2, 1/3, 1/6])) #correspond à m=3\n",
    "\n",
    "# Nouveau : beaucoup plus vite\n",
    "value_1 = np.array([-1, 1])\n",
    "value_2 = np.array([-3, -2, -2, -1, -1, -1, 1, 1, 1, 2, 2, 3])\n",
    "saut_1 = lambda x : value_1[np.random.randint(low=2, size=x)]\n",
    "saut_2 = lambda x : value_2[np.random.randint(low=12, size=x)]\n",
    "\n",
    "# Les paramètres\n",
    "P0 = 35\n",
    "T = 4*60*60\n",
    "lamb = 1/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Echantillionage d'importance\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)# Function is compiled to machine code when called the first time\n",
    "def inf_echantillon_importance(N, J, P0, lambT, s, f_dic): \n",
    "  ruines = 0\n",
    "  for i in range(len(N) - 1):\n",
    "    somme = P0\n",
    "    ruine = 0.\n",
    "    for j in range(N[i], N[i + 1]):\n",
    "      somme += J[j]\n",
    "      if somme < 0:\n",
    "        # Calculer L_T\n",
    "        X_T_f = np.sum(f_dic[ J[N[i]:N[i+1]] ])\n",
    "        L_T = np.exp(X_T_f - (s - 1) * lambT)\n",
    "        ruine = 1 / L_T\n",
    "        break\n",
    "    ruines += ruine\n",
    "  return ruines\n",
    "\n",
    "def trajectoire_importance(P0, T, lamb, m, size, f):\n",
    "  if m == 1:\n",
    "    value = np.array([-1, 1])\n",
    "    p = np.array([1/2, 1/2])\n",
    "  else:\n",
    "    value = np.array([-3, -2, -1, 1, 2, 3])\n",
    "    p = np.array([1 / 12, 1 / 6, 1 / 4, 1 / 4, 1 / 6, 1 / 12])\n",
    "    \n",
    "  # Nouvelle loi\n",
    "  s = np.sum(np.exp(f(value)) * p)\n",
    "  new_lamb = lamb * s\n",
    "  new_p = np.exp(f(value)) * p / s\n",
    "  \n",
    "  # f_dic : i -> f(i) sous la forme dictionnaire\n",
    "  f_dic = np.zeros(10)\n",
    "  for i in value:\n",
    "    f_dic[i] = f(i)\n",
    "  print(s)\n",
    "  print(new_lamb * T * np.sum(value * new_p)) # Esperance (On veut que ce soit environ 0)\n",
    "  #if abs(new_lamb * T * np.sum(value * new_p)) > 100:\n",
    "  #  return 0\n",
    "  N = np.random.poisson(lam=new_lamb * T, size=size + 1)\n",
    "  N[0] = 0\n",
    "  N = N.cumsum()                    # La valeur N[i] - N[i - 1] est égale à Ni pour le i-ième échantillon\n",
    "                                    # Donc la somme des sauts entre indice N[i] et N[i + 1] - 1 suit la loi voulue\n",
    "  \n",
    "  J = np.random.choice(value, size=N[-1] + 1, p=new_p)\n",
    "  res = inf_echantillon_importance(N, J, P0, lamb * T, s, f_dic)\n",
    "  proba = res / size\n",
    "  return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6487212707001282\n",
      "4.3930759582092675e-15\n",
      "0.005009256970206878\n",
      "0.00013837328366338213\n",
      "CPU times: user 1.77 s, sys: 389 ms, total: 2.16 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = 3\n",
    "M = int(1e6)\n",
    "f = lambda x : 0.5\n",
    "\n",
    "p_r = trajectoire_importance(P0, T, lamb, 3, M, f)\n",
    "R_IC = 1.96*np.sqrt(p_r*(1-p_r))/np.sqrt(M) #rayon de l'intervalle de confiance\n",
    "print(p_r)\n",
    "print(R_IC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ljp4VlmzfJ4"
   },
   "outputs": [],
   "source": [
    "## Monte-Carlo Naif avec numba\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def inf_echantillon(N, J, P0): # Function is compiled to machine code when called the first time\n",
    "  ruines = 0\n",
    "  for i in range(len(N) - 1):\n",
    "    somme = P0\n",
    "    ruine = 0\n",
    "    for j in range(N[i], N[i + 1]):\n",
    "      somme += J[j]\n",
    "      if somme < 0:\n",
    "        ruine = 1\n",
    "        break\n",
    "    ruines += ruine\n",
    "  return ruines\n",
    "\n",
    "def trajectoire(P0, T, lamb, saut, size):\n",
    "  if size > int(1e7):\n",
    "    sizes = size\n",
    "    size = int(1e7)\n",
    "    proba = 0\n",
    "    for i in range(sizes // size):\n",
    "      N = np.random.poisson(lam=lamb * T, size=size + 1)\n",
    "      N[0] = 0\n",
    "      N = N.cumsum()                    # La valeur N[i] - N[i - 1] est égale à Ni pour le i-ième échantillon\n",
    "                                        # Donc la somme des sauts entre indice N[i] et N[i + 1] - 1 suit la loi voulue\n",
    "      J = saut(N[-1] + 1)\n",
    "      res = inf_echantillon(N, J, P0)\n",
    "      proba += res / size / (sizes // size)\n",
    "    return proba\n",
    "  else:\n",
    "    N = np.random.poisson(lam=lamb * T, size=size + 1)\n",
    "    N[0] = 0\n",
    "    N = N.cumsum()                    # La valeur N[i] - N[i - 1] est égale à Ni pour le i-ième échantillon\n",
    "                                      # Donc la somme des sauts entre indice N[i] et N[i + 1] - 1 suit la loi voulue\n",
    "    J = saut(N[-1] + 1)\n",
    "    res = inf_echantillon(N, J, P0)\n",
    "    proba = res / size\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "gL8w_R_83lQb",
    "outputId": "6b0f3a12-8fa7-40a8-9853-cc783a28bf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004342\n",
      "0.00012887125999809886\n",
      "CPU times: user 593 ms, sys: 117 ms, total: 710 ms\n",
      "Wall time: 711 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "M = int(1e6)\n",
    "p_r = trajectoire(P0, T, lamb, saut_2, size=M)\n",
    "R_IC = 1.96*np.sqrt(p_r*(1-p_r))/np.sqrt(M) #rayon de l'intervalle de confiance\n",
    "print(p_r)\n",
    "print(R_IC)\n",
    "\n",
    "#print(trajectoire(P0, T, lamb, saut_1, size=int(1e7)))\n",
    "\n",
    "#m=1\n",
    "#0.00279 pour P0 = 20 M = 10^5 (total time 161 ms)\n",
    "#5e-07 pour P0=35 et M=10^7 total time : 16.1 s\n",
    "#quand on fait la moyenne sur 10 essais à M=10^7, on trouve proba_emp = 2.009975 e-7 et sigma_emp = 3.6 e-7 (tout ça pour m=1)\n",
    "\n",
    "#m=3\n",
    "#proba_emp=0.0043245, sigma_emp = 7.1273066441679e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEpbJndTyvwM"
   },
   "outputs": [],
   "source": [
    "## Splitting et MCMC - Méthode 3\n",
    "\n",
    "\n",
    "\n",
    "def NiveauxSplitting(a,seuil,n,lamb,T,p,P0,saut):\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction qui renvoie une estimation des niveaux\n",
    "    de splitting a_1, a_2, ..., a_k tels que P(Phi_T <= a_k | Phi_T <= a_{k-1}) = 0.1 = seuil\n",
    "    (où Phi_T : inf de P_t pour t dans [0;T])\n",
    "    Ces niveaux sont des quantiles d'une loi conditionnelle.\n",
    "    On utilise l'inversion de la fonction de repartition empirique de \n",
    "    cette loi afin d'estimer un quantile par\n",
    "    le quantile empirique.\n",
    "    On a a = a_k < a_{k-1} < ... < a_0= + infini (dans notre problème, a = 0)\n",
    "    La fonction renvoie quantiles = [a_1, ..., a_k]\n",
    "    \"\"\"\n",
    "    ## Estimation du premier niveau a_1: c'est le \n",
    "    ## quantile d'une loi non conditionnelle.\n",
    "    ## On l'estime ici par la methode ergodique\n",
    "\n",
    "    liste_Phi = np.zeros(n)\n",
    "\n",
    "    liste_sauts = liste_sts(lamb,T,saut)\n",
    "\n",
    "    for l in range(n):\n",
    "        coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "\n",
    "        liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "        new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "        new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "        liste_sauts = new_liste_sauts\n",
    "        liste_Phi[l] = Phi(liste_sauts,P0)\n",
    "\n",
    "    liste_Phi.sort()\n",
    "\n",
    "    quantiles = np.array([liste_Phi[int(np.ceil(seuil*n))-1]])    \n",
    "\n",
    "    while quantiles[-1] > a:\n",
    "        print(\"Inside while\")\n",
    "        liste_Phi = np.zeros(n)\n",
    "\n",
    "        \n",
    "        while Phi(liste_sauts,P0)>=quantiles[-1]:\n",
    "            liste_sauts = liste_sts(lamb,T,saut)\n",
    "        ## Simulation du processus AR(1) conditionnel\n",
    "    \n",
    "        for l in range(n):\n",
    "            coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "\n",
    "            liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "            new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "            new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "            if Phi(new_liste_sauts,P0)<quantiles[-1]:\n",
    "                liste_sauts = new_liste_sauts\n",
    "\n",
    "            liste_Phi[l] = Phi(liste_sauts,P0)\n",
    "    \n",
    "        liste_Phi.sort()\n",
    "        quantiles = np.append(quantiles, liste_Phi[int(np.ceil(seuil*n))-1] )\n",
    "\n",
    "    \n",
    "    ## On selectionne les niveaux a_{k-1},..., a_1 strictement au dessus de a\n",
    "    quantiles = quantiles[:-1]\n",
    "    ## On rajoute a\n",
    "    quantiles = np.append(quantiles,a)\n",
    "\n",
    "    return quantiles\n",
    "\n",
    "\n",
    "def Phi(liste_sauts,P0):#fonction qui renvoie l'inf des valeurs de X aux instants de saut\n",
    "    #ie l'inf de P0+cumsum(incréments) \n",
    "    if len(liste_sauts[0]) == 0:\n",
    "        return P0\n",
    "    liste_prix = P0+np.cumsum(liste_sauts[1,:])\n",
    "    prix_min = np.min(liste_prix)\n",
    "    return prix_min\n",
    "\n",
    "def liste_sts(lbda,T,saut):\n",
    "    \n",
    "    N = np.random.poisson(lbda*T)\n",
    "    liste_temps_sauts = np.random.uniform(low = 0, high = T, size = N)\n",
    "    liste_temps_sauts_triee = [np.sort(liste_temps_sauts)]\n",
    "    liste_increments = [saut(N)]\n",
    "    #renvoie un array de N colonnes et 2 lignes: 1ere ligne pour les temps des sauts (T_n), deuxième ligne pour leurs amplitudes (J_n)\n",
    "    return np.concatenate((liste_temps_sauts_triee,liste_increments),axis=0)\n",
    "\n",
    "def tri_temps(new_liste_sauts):\n",
    "    ordre = [new_liste_sauts[0,:].argsort()]\n",
    "    liste_sauts_triee = np.take_along_axis(new_liste_sauts, np.concatenate((ordre,ordre),axis=0), axis=1) \n",
    "    return liste_sauts_triee\n",
    "\n",
    "\n",
    "def MCMC(M,p,lamb,liste_a,P0,saut): \n",
    "\n",
    "    liste_pi = np.zeros(len(liste_a)) #estimateurs des probabilités conditionnelles\n",
    "\n",
    "    liste_indicatrices = np.zeros(M,dtype=bool) \n",
    "    \"\"\"\n",
    "    le k-ieme élém. de liste_indicatrices vaut True si le prix devient négatif avant l'instant T lors du k-ieme essai; False sinon\n",
    "    \"\"\"\n",
    "\n",
    "    #Loi non conditionnelle\n",
    "    \n",
    "    liste_sauts = liste_sts(lamb,T,saut) \n",
    "\n",
    "\n",
    "    for l in range(M):\n",
    "        coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "\n",
    "        liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "        new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "        new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "        liste_sauts = new_liste_sauts\n",
    "        liste_indicatrices[l] = (Phi(liste_sauts,P0)<liste_a[0])\n",
    "\n",
    "    liste_pi[0] = np.mean(liste_indicatrices)\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "    for k in range(1,len(liste_a)):\n",
    "        liste_indicatrices = np.zeros(M,dtype=bool)  \n",
    "\n",
    "        #Initialisation \n",
    "\n",
    "        while Phi(liste_sauts,P0)>=liste_a[k-1]:\n",
    "          \n",
    "            liste_sauts = liste_sts(lamb,T,saut)\n",
    "\n",
    "      \n",
    "        for l in range(M):\n",
    "            coloriage = liste_sauts[:,np.random.binomial(1,p,size = len(liste_sauts[0])) ==1]\n",
    "\n",
    "            liste_sauts_tilde = liste_sts((1-p)*lamb,T,saut)\n",
    "            new_liste_sauts = np.concatenate((coloriage,liste_sauts_tilde),axis=1)\n",
    "            new_liste_sauts = tri_temps(new_liste_sauts)\n",
    "\n",
    "            if Phi(new_liste_sauts,P0)< liste_a[k-1]:\n",
    "                liste_sauts = new_liste_sauts\n",
    "            liste_indicatrices[l] = (Phi(liste_sauts,P0) < liste_a[k])\n",
    "\n",
    "\n",
    "        liste_pi[k] = np.mean(liste_indicatrices)\n",
    "    \n",
    "\n",
    "    proba_prix_negatif = np.prod(liste_pi)\n",
    "        \n",
    "    return proba_prix_negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NbRoSLDPkPMB",
    "outputId": "aecba370-6233-4de4-96c1-fca931b9c36e"
   },
   "outputs": [],
   "source": [
    "P0 = 35 \n",
    "T = 4*60*60 #conversion en secondes\n",
    "lamb =  1/300 \n",
    "M = int(1e4) \n",
    "\n",
    "a=0\n",
    "\n",
    "\n",
    "#Choix des paramètres pour les niveaux de splitting et la simulation par chaîne de Markov\n",
    "seuil = 0.03\n",
    "p=0.5\n",
    "\n",
    "liste_a = NiveauxSplitting(a,seuil,M,lamb,T,p,P0,saut_1)\n",
    "print(liste_a)\n",
    "#Donne [22. 14.  8.  3.  0.] pour m=1 et seuil = 0.05\n",
    "#Donne [20.  9.  1.  0.] pour m=3 et seuil = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dKnmd80stXp4",
    "outputId": "421f5a86-65b5-43d2-b834-b3351a7441a0"
   },
   "outputs": [],
   "source": [
    "probas = np.zeros(10)\n",
    "\n",
    "M = int(1e5)\n",
    "n=10\n",
    "\n",
    "for i in range(n):\n",
    "    probas[i] = MCMC(M, p,lamb,liste_a,P0,saut_1)\n",
    "\n",
    "proba_emp = np.mean(probas)\n",
    "sigma_emp = np.std(probas)/np.sqrt(n) #écart-type empirique de la moyenne des n estimateurs\n",
    "print(proba_emp)\n",
    "print(sigma_emp)\n",
    "#Réponse pour m=1 ie k=0 et P0=35 : proba = 3.333674930684664e-07, variance = 5 10^-8\n",
    "#m=3 et P0=35: proba = 0.004309577501008395, variance = 0.00010259619121779947\n",
    "#m=1 liste_a = [24. 17. 12.  7.  3.  0.] seuil =0.1 M=10^4 n=10 proba_emp=4.619226215866903e-07 sigma_emp= 9.561801048257746e-08\n",
    "#m=1 liste_a= [20. 12.  5.  0.] seuil = 0.03 P0=35 M=10^4 n=10 proba_emp = 3.6218700696e-07 sigma_emp = 7.599237232859178e-08 \n",
    "#same avec M=10^5 proba_emp = 3.4354401671979703e-07. sigma_emp= 1.3033966706232877e-08 LE MEILLEUR QU ON AIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yXOlLPEjIbD9",
    "outputId": "d0d2b7dc-d123-4604-9ee4-cb0f9c9d08a5"
   },
   "outputs": [],
   "source": [
    "print(\"Estimation de la probabilité de ruine pour m=1 par méthode de Splitting/MCMC: {:09.8f}+/-{:09.8f}\".format(proba_emp,sigma_emp))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "XO0iJelvzaxI",
    "cCgK9NrFzQfO",
    "f6ZpnHtBhElE",
    "ntNKzkWPzUT1",
    "fKihS64UzPW5",
    "GoJBPfJ4T0FL",
    "GiQmq9gl0gSv"
   ],
   "machine_shape": "hm",
   "name": "Projet_Modal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
